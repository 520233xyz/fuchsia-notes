\section{appmgr}

appmgr的启动

\begin{verbatim}

static const char* argv_appmgr[] = { "/system/bin/appmgr" };
appmgr_hnds[0] = appmgr_req_srv;
devmgr_launch(fuchsia_job_handle, "appmgr", countof(argv_appmgr),
                argv_appmgr, NULL, -1, appmgr_hnds, appmgr_ids,
                appmgr_hnd_count, NULL, FS_FOR_APPMGR);

    env是空
    launchpad_create(job_copy, name, &lp);
        launchpad_create_with_jobs(job, xjob, name, result);
            zx_process_create(creation_job, name, name_len, 0, &proc, &vmar);
            launchpad_create_with_process(proc, vmar, &lp)
    
    file_vmo = devmgr_load_file("/system/bin/appmgr")
        bootfs_open(&bootfs, path + 6, &vmo);
            zx_vmo_clone(bfs->vmo, ZX_VMO_CLONE_COPY_ON_WRITE,
                          e->data_off, e->data_len, &vmo)
    launchpad_load_from_vmo(lp, file_vmo)
        launchpad_file_load_with_vdso(lp, vmo);
            launchpad_file_load(lp, vmo);
                launchpad_elf_load_body(lp, first_line, to_read, vmo);
                    不是脚本，作为elf 加载
                    elf_load_start(vmo, hdr_buf, buf_sz, &elf)
                    elf_load_get_interp(elf, vmo, &interp, &interp_len)
                    handle_interp(lp, vmo, interp, interp_len)
                        加载动态连接器
                        elf_load_start(interp_vmo, NULL, 0, &elf)
                        elf_load_finish(lp_vmar(lp), elf, interp_vmo,
                                 &segments_vmar, &lp->base, &lp->entry);
                        真正的exe vmo会作为HND_EXEC_VMO类型的handle传给ld.so


            launchpad_load_vdso(lp, ZX_HANDLE_INVALID);
                launchpad_elf_load_extra(lp, vmo, &lp->vdso_base, NULL);
                    elf_load_start(vmo, NULL, 0, &elf)
                    elf_load_finish(lp_vmar(lp), elf, vmo, NULL, base, entry)

            launchpad_add_vdso_vmo(lp);

    launchpad_go(lp, proc, &errmsg)
        launchpad_start(lp, &h);
            prepare_start(lp, "initial-thread", to_child, &thread, &sp);
                zx_thread_create(lp_proc(lp), thread_name,strlen(thread_name), 0, thread);
                send_loader_message(lp, *thread, to_child);
                    把arg, env, names作为消息发送给新进程
                    names包含了那些appmgr可见的namespace的路径，定义在devmgr-fdio.c:FSTAB
                
                create stack vmo for the new thread

            zx_process_start(proc, thread, lp->entry, sp, child_bootstrap, lp->vdso_base);

动态链接库是libc.so. 入口在dl-entry.S文件里。这里会链接真正的可执行文件，找到
它的入口地址，进入它。实现在zircon/third_party/ulib/musl/ldso/dynlink.c

这里推测，fuchsia认为动态链接是libc的功能，不是libzircon的功能。

可执行文件的入口在zircon/third_party/ulib/musl/arch/aarch64/Scrt1.S

__libc_start_main()设置一些全局变量
__environ
__zircon_process_self;
__zircon_vmar_root_self;
__zircon_job_default;
main_thread_handle

__allocate_thread分配线程需要的内存

进入start_main()，调用构造函数。进入main!

argv = "/system/bin/appmgr"


async::Loop loop(&kAsyncLoopConfigMakeDefault)
    async_loop_create(config, &loop_)
    
fs::SynchronousVfs vfs(loop.async())
    缺省构造函数

component::RootLoader root_loader
    一个服务，用的fidl接口

directory->AddEntry(
    component::Loader::Name_, //"component.Loader"
    fbl::AdoptRef(new fs::Service([&root_loader](zx::channel channel) {
        root_loader.AddBinding(
            fidl::InterfaceRequest<component::Loader>(std::move(channel)));
        return ZX_OK;
    })));

vfs.ServeDirectory(directory, std::move(h2)
    请求应该是从h2进来
    // Tell the calling process that we've mounted the directory.
    r = channel.signal_peer(0, ZX_USER_SIGNAL_0)
    vn->Serve(this, fbl::move(channel), ZX_FS_RIGHT_ADMIN);
        vfs->ServeConnection(fbl::make_unique<Connection>(vfs, fbl::WrapRefPtr(this), fbl::move(channel), flags));
            connection->Serve()
                wait_.set_object(channel_.get());
                    wait_.object = object;
                wait_.Begin(vfs_->async());
                    async_begin_wait(async, &wait_)
                        async->ops->v1.begin_wait(async, wait)
                            zx_object_wait_async(
                                wait->object, loop->port, (uintptr_t)wait, wait->trigger, ZX_WAIT_ASYNC_ONCE);
                            把前面那个h2挂到async loop的port上

component::Realm root_realm(nullptr, std::move(h1), kRootLabel)
    zx::channel::create(0, &svc_channel_server_, &svc_channel_client_)
    default_namespace_->services().set_backing_dir(std::move(host_directory))
    default_namespace_->services().AddBinding(service_provider.NewRequest());
        zx::channel::create(0, &h1, &h2) 
        Bind(std::move(h1), async) 
        return InterfaceRequest<Interface>(std::move(h2));

        ServiceProviderBridge::AddBinding
            bindings_.AddBinding(this, std::move(request));
                bindings_.push_back

    loader_ = ConnectToService<Loader>(service_provider.get());
        service_provider->ConnectToService(interface_name,
                               interface_ptr.NewRequest().TakeChannel());

    这里没太看懂。应该是service_provider和Loader服务建立联系了。
    default_namespace_->services()是ServiceProviderBridge，它继承了ServiceProvider
    service_provider是InterfacePtr<ServiceProvider>
    NewRequest()建立与ServiceProvider服务端的通道，返回之，存到bindings里面。
    把与Loader的通道发送给ServiceProvider服务端。

PublishRootDir(&root_realm, &publish_vfs);
    把从devmgr发来的通道挂到目录服务上


------------------------------------------------------

下面这些结构用来模拟unix fd io

typedef struct {
    mtx_t lock;
    mtx_t cwd_lock;
    bool init;
    mode_t umask;
    fdio_t* root;
    fdio_t* cwd;
    fdio_t* fdtab[FDIO_MAX_FD];
    fdio_ns_t* ns;
    char cwd_path[PATH_MAX];
} fdio_state_t;

extern fdio_state_t __fdio_global_state;

#define fdio_lock (__fdio_global_state.lock)
#define fdio_root_handle (__fdio_global_state.root)
#define fdio_cwd_handle (__fdio_global_state.cwd)
#define fdio_cwd_lock (__fdio_global_state.cwd_lock)
#define fdio_cwd_path (__fdio_global_state.cwd_path)
#define fdio_fdtab (__fdio_global_state.fdtab)
#define fdio_root_init (__fdio_global_state.init)
#define fdio_root_ns (__fdio_global_state.ns)

typedef struct async_dispatcher async_t;

static const async_ops_t async_loop_ops = {
    .version = ASYNC_OPS_V1,
    .reserved = 0,
    .v1 = {
        .now = async_loop_now,
        .begin_wait = async_loop_begin_wait,
        .cancel_wait = async_loop_cancel_wait,
        .post_task = async_loop_post_task,
        .cancel_task = async_loop_cancel_task,
        .queue_packet = async_loop_queue_packet,
        .set_guest_bell_trap = async_loop_set_guest_bell_trap,
    },
};

vfs.ServeDirectory(directory, std::move(h2)

PublishRootDir(&root_realm, &publish_vfs);

async::PostTask(async_t* async, fbl::Closure handler)
    PostTaskForTime(async, static_cast<fbl::Closure&&>(handler),async::Now(async));
        async_post_task(async, task);
            async->ops->v1.post_task(async, task);

root_realm.CreateApplication(std::move(launch_info), sysmgr.NewRequest());


Classify出来的应该是kProcess
CreateApplicationWithProcess(std::move(package), std::move(launch_info),
                             std::move(controller), std::move(ns));
zx::process process = CreateProcess(job_for_child_, std::move(executable), url,
                                    std::move(launch_info), zx::channel(), builder.Build());

\end{verbatim}